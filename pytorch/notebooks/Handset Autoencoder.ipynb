{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "\n",
    "sys.path.insert(0, '/home/eharper/github_projects/ericharper/dataloaders/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from batch_dataloader import BatchDataLoader\n",
    "# from batch_dataset import BatchDataset\n",
    "# from batch_dataset import TensorBatchDataset\n",
    "\n",
    "from pytorch.batch_dataloader.parquet_batch_dataset import ParquetBatchDataset\n",
    "from pytorch.batch_dataloader.parquet_batch_dataloader import ParquetBatchDataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PARQUET = '/raid/data/handset_data/train_parquet_swapped'\n",
    "TEST_PARQUET = '/raid/data/handset_data/test_parquet_swapped'\n",
    "\n",
    "NUMERIC_COLS = ['main_Device_ScreenResolution_Width', 'main_Device_ScreenResolution_Height', 'main_Device_Memory',\n",
    "                'main_Device_Storage', 'main_QOS_Location_Latitude', 'main_QOS_Location_Longitude', \n",
    "                'main_QOS_Location_Altitude', 'main_QOS_Location_HorizontalAccuracy', 'main_QOS_Location_VerticalAccuracy',\n",
    "                'main_QOS_Jitter_Average', 'main_QOS_PacketLoss_LostPercentage', 'main_QOS_Velocity_Speed', \n",
    "                'main_QOS_Velocity_Bearing', 'main_QOS_DeviceFreeMemory', 'main_QOS_DeviceCPU', \n",
    "                'main_QOS_DeviceBatteryLevel', 'main_QOS_DeviceFreeStorage', 'main_QOS_DeltaTransmittedBytes',\n",
    "                'main_QOS_DeltaReceivedBytes', 'main_QOS_SystemUptime', 'main_QOS_DeviceUsedStorage', 'main_QOS_DeviceUsedMemory']\n",
    "\n",
    "MAX_ORDS = {\"main_ConnectionType\": 3, \"main_ConnectionTechnology\": 13, \"main_ServiceProvider\": 979, \"main_Device_Manufacturer\": 465, \"main_Device_OS\": 28, \"main_Device_DeviceLanguage\": 54, \"main_Region\": 53, \"conn_Generation_Category\": 3, \"sp_ServiceProviderBrandName\": 76, \"main_QOS_DeviceBatteryState\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_card_dict = {k:v+1 for (k,v) in MAX_ORDS.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding_dims(cat_card_dict):\n",
    "    cat_embedding_dict = {k:max(int(np.ceil(v / 100.0)), 2) for (k,v) in cat_card_dict.items()} \n",
    "    return cat_embedding_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_embedding_dict = compute_embedding_dims(cat_card_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 10\n",
    "#NUM_FILES_PER_DATASET = 200\n",
    "#NUM_FILES_PER_DATASET = 20\n",
    "NUM_FILES_PER_DATASET = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parquet_filepaths = glob.glob(TRAIN_PARQUET + '/*.parquet')\n",
    "test_parquet_filepaths = glob.glob(TEST_PARQUET + '/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, cont_name_list, cat_card_dict, cat_embedding_dict, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.cont_name_list = cont_name_list\n",
    "        self.cat_card_dict = cat_card_dict\n",
    "        self.cat_embedding_dict = cat_embedding_dict\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        \n",
    "        self.embedding_layers = nn.ModuleList(\n",
    "            [nn.Embedding(self.cat_card_dict[cat], self.cat_embedding_dict[cat])\n",
    "             for cat in self.cat_card_dict.keys()]\n",
    "        )\n",
    "        \n",
    "        for idx, layer in enumerate(self.embedding_layers):\n",
    "            print((idx, layer))\n",
    "        \n",
    "        self.encoder_input_dim = len(self.cont_name_list) + sum(self.cat_embedding_dict.values())\n",
    "            \n",
    "        self.decoder_out_dim = len(self.cont_name_list) + sum(self.cat_card_dict.values()) + len(cat_card_dict)\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.encoder_input_dim, 96),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(.1),\n",
    "            nn.Linear(96, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(.1),\n",
    "            nn.Linear(64, 48),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(.1),\n",
    "            nn.Linear(48, 16),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(.1),\n",
    "            nn.Linear(16, self.latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.latent_dim, 16),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(.1),\n",
    "            nn.Linear(16, 48),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(.1),\n",
    "            nn.Linear(48, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(.1),\n",
    "            nn.Linear(64, 96),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(.1),\n",
    "            nn.Linear(96, self.decoder_out_dim),\n",
    "            #nn.ReLU()\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, cat_array, cont_array):\n",
    "        #print(cat_array.shape)\n",
    "        embedded = [embedding_layer(cat_array[:, idx])\n",
    "                    for idx, embedding_layer in enumerate(self.embedding_layers)] \n",
    "            \n",
    "        embedded = torch.cat(embedded, 1)\n",
    "        \n",
    "        encoder_input = torch.cat([embedded, cont_array], 1)\n",
    "        encoded = self.encoder(encoder_input)\n",
    "        decoded = self.decoder(encoded)\n",
    "        \n",
    "        return decoded, encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCE_MSE_Loss(torch.nn.Module):\n",
    "    def __init__(self, cont_name_list, cat_card_dict, cat_embedding_dict):\n",
    "        super().__init__()\n",
    "        self.cont_name_list = cont_name_list\n",
    "        self.cat_card_dict = cat_card_dict\n",
    "        \n",
    "        self.decoder_cat_indices = [0]\n",
    "        for idx, cat_card in enumerate(self.cat_card_dict.values()):\n",
    "            self.decoder_cat_indices += [self.decoder_cat_indices[idx] + cat_card]\n",
    "        \n",
    "        self.decoder_cont_idx = -len(cont_name_list)\n",
    "        \n",
    "    def forward(self, decoder_out, cat_array, cont_array):\n",
    "        #cat_loss = sum([F.cross_entropy(decoder_out[:, decoder_cat_idx:self.decoder_cat_indices[cat_idx + 1]], cat_array[:, cat_idx])\n",
    "        #                for cat_idx, decoder_cat_idx in enumerate(self.decoder_cat_indices[0:-1])])\n",
    "        cat_loss = 0\n",
    "        for cat_idx, decoder_cat_idx in enumerate(self.decoder_cat_indices[0:-1]):\n",
    "            cat_loss += F.cross_entropy(decoder_out[:, decoder_cat_idx:self.decoder_cat_indices[cat_idx + 1]], cat_array[:, cat_idx])\n",
    "        \n",
    "        cont_loss = F.mse_loss(decoder_out[:, self.decoder_cont_idx:], cont_array)\n",
    "        \n",
    "        w = sum(self.cat_card_dict.values())\n",
    "        \n",
    "        loss = (cat_loss / w) + cont_loss\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, Embedding(4, 2))\n",
      "(1, Embedding(14, 2))\n",
      "(2, Embedding(980, 10))\n",
      "(3, Embedding(466, 5))\n",
      "(4, Embedding(29, 2))\n",
      "(5, Embedding(55, 2))\n",
      "(6, Embedding(54, 2))\n",
      "(7, Embedding(4, 2))\n",
      "(8, Embedding(77, 2))\n",
      "(9, Embedding(5, 2))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:3\")\n",
    "autoencoder = Autoencoder(NUMERIC_COLS, cat_card_dict, cat_embedding_dict, LATENT_DIM)\n",
    "autoencoder = autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MCE_MSE_Loss(NUMERIC_COLS, cat_card_dict, cat_embedding_dict)\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples: 272978846\n",
      "Total batches: 910\n",
      "CPU times: user 1min 34s, sys: 24.9 s, total: 1min 59s\n",
      "Wall time: 9.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset = ParquetBatchDataset(train_parquet_filepaths,\n",
    "                                    num_files_per_chunk=NUM_FILES_PER_DATASET,\n",
    "                                    batch_size=300000)\n",
    "total_train_samples = sum(train_dataset.compute_samples_per_chunk())\n",
    "print('Total Samples:', total_train_samples)\n",
    "train_data_loader = ParquetBatchDataLoader(train_dataset, total_train_samples,\n",
    "                                           shuffle=True, drop_last=False)\n",
    "\n",
    "print('Total batches:', len(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for batch_idx, batch in enumerate(train_data_loader):\n",
    "#    print(batch[0][0:10])\n",
    "    #print('Batch Idx: %d | Batch Shape: (%d, %d)' % (batch_idx, batch[0].shape[0], batch[0].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading chunk 0 from disk.\n",
      "Rows per second: 220918.80251093893\n",
      "Epoch 0 | Batch 0 | Loss 0.1359\n",
      "Rows per second: 333599.4795143619\n",
      "Epoch 0 | Batch 100 | Loss 0.0495\n",
      "Rows per second: 332132.0397083088\n",
      "Epoch 0 | Batch 200 | Loss 0.0533\n",
      "Rows per second: 334225.15559255326\n",
      "Epoch 0 | Batch 300 | Loss 0.0454\n",
      "Rows per second: 331593.7562011207\n",
      "Epoch 0 | Batch 400 | Loss 0.0466\n",
      "Loading chunk 1 from disk.\n",
      "Rows per second: 332038.4368250433\n",
      "Epoch 0 | Batch 500 | Loss 0.0492\n",
      "Rows per second: 333757.0731238931\n",
      "Epoch 0 | Batch 600 | Loss 0.0455\n",
      "Rows per second: 332505.9251897395\n",
      "Epoch 0 | Batch 700 | Loss 0.0423\n",
      "Rows per second: 333523.87682405015\n",
      "Epoch 0 | Batch 800 | Loss 0.0404\n",
      "Rows per second: 331089.96800642874\n",
      "Epoch 0 | Batch 900 | Loss 0.0414\n",
      "Total Training Duration: 868.1286525726318\n",
      "Total Batch Duration: 818.3920609951019\n",
      "Data loading proportion: 0.05729172908893098\n"
     ]
    }
   ],
   "source": [
    "autoencoder.train()\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "training_start_time = time.time()\n",
    "\n",
    "total_batch_time = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_data_loader):\n",
    "        batch_train_start = time.time()\n",
    "        \n",
    "        batch = batch[0]\n",
    "        \n",
    "        num_batch_rows = batch.shape[0]\n",
    "\n",
    "        cat_array = batch[:, 0:len(cat_card_dict)].long()\n",
    "        cont_array = batch[:, -len(NUMERIC_COLS):].float()\n",
    "        cat_array = cat_array.to(device)\n",
    "        cont_array = cont_array.to(device)\n",
    "\n",
    "        decoder_out, encoder_out = autoencoder(cat_array, cont_array)\n",
    "\n",
    "        loss = criterion(decoder_out, cat_array, cont_array)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        batch_train_duration = time.time() - batch_train_start\n",
    "        total_batch_time += batch_train_duration\n",
    "        rows_per_second = num_batch_rows / batch_train_duration\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Rows per second:', rows_per_second)\n",
    "            print('Epoch %d | Batch %d | Loss %.4f' %\n",
    "                  (epoch, batch_idx, loss.item())\n",
    "                 )\n",
    "\n",
    "total_training_time = time.time() - training_start_time\n",
    "print('Total Training Duration:', total_training_time) \n",
    "print('Total Batch Duration:', total_batch_time)\n",
    "print('Data loading proportion:', (total_training_time - total_batch_time) / total_training_time)\n",
    "    \n",
    "torch.save(autoencoder.state_dict(), \"./autoencoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples: 68239502\n",
      "Total batches: 228\n",
      "CPU times: user 24 s, sys: 5.92 s, total: 29.9 s\n",
      "Wall time: 2.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_dataset = ParquetBatchDataset(test_parquet_filepaths,\n",
    "                                    num_files_per_chunk=NUM_FILES_PER_DATASET,\n",
    "                                    batch_size=300000)\n",
    "total_test_samples = sum(test_dataset.compute_samples_per_chunk())\n",
    "print('Total Samples:', total_test_samples)\n",
    "test_data_loader = ParquetBatchDataLoader(test_dataset, total_test_samples,\n",
    "                                           shuffle=False, drop_last=False)\n",
    "\n",
    "print('Total batches:', len(test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, Embedding(4, 2))\n",
      "(1, Embedding(14, 2))\n",
      "(2, Embedding(980, 10))\n",
      "(3, Embedding(466, 5))\n",
      "(4, Embedding(29, 2))\n",
      "(5, Embedding(55, 2))\n",
      "(6, Embedding(54, 2))\n",
      "(7, Embedding(4, 2))\n",
      "(8, Embedding(77, 2))\n",
      "(9, Embedding(5, 2))\n",
      "Loading chunk 0 from disk.\n",
      "Inferences per second: 2538115.774228555\n",
      "Batch 0 | Loss 0.0364\n",
      "Inferences per second: 2805911.119138887\n",
      "Batch 100 | Loss 0.0362\n",
      "Inferences per second: 2828758.5343317874\n",
      "Batch 200 | Loss 0.0362\n",
      "Testing duration: 28.2793128490448\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "device = torch.device(\"cuda:3\")\n",
    "autoencoder = Autoencoder(NUMERIC_COLS, cat_card_dict, cat_embedding_dict, LATENT_DIM)\n",
    "autoencoder.load_state_dict(torch.load(\"./autoencoder.pt\"))\n",
    "autoencoder = autoencoder.to(device)\n",
    "autoencoder.eval()\n",
    "criterion = MCE_MSE_Loss(NUMERIC_COLS, cat_card_dict, cat_embedding_dict)\n",
    "\n",
    "test_start = time.time()\n",
    "\n",
    "for batch_idx, batch in enumerate(test_data_loader):\n",
    "    batch_start = time.time()\n",
    "    batch = batch[0]\n",
    "    num_rows = batch.shape[0]\n",
    "\n",
    "    cat_array = batch[:, 0:len(cat_card_dict)].long()\n",
    "    cont_array = batch[:, -len(NUMERIC_COLS):].float()\n",
    "    \n",
    "    # TODO: fix preprocessing - ordinal encoder may encode -1's on test data\n",
    "    cat_array = cat_array.abs()\n",
    "    \n",
    "    cat_array = cat_array.to(device)\n",
    "    cont_array = cont_array.to(device)\n",
    "\n",
    "    decoder_out, encoder_out = autoencoder(cat_array, cont_array)\n",
    "\n",
    "    loss = criterion(decoder_out, cat_array, cont_array)\n",
    "\n",
    "    # print statistics\n",
    "    batch_duration = time.time() - batch_start\n",
    "    inferences_per_second = num_rows / batch_duration\n",
    "    if batch_idx % 100 == 0:\n",
    "        print('Inferences per second:', inferences_per_second)\n",
    "        print('Batch %d | Loss %.4f' % (batch_idx, loss.item())\n",
    "             )\n",
    "\n",
    "print(\"Testing duration:\", time.time() - test_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
